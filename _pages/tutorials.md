---
title: Tutorials
layout: single
excerpt: "ACL 2017 Tutorials."
permalink: /tutorials/
sidebar: false

---
{% include base_path %}

The following tutorials have been accepted for ACL 2017 and will be held on Sunday, July 30th, 2017. Exact timings will be posted as part of the official program.

## Morning


<span class="btn btn--small">T1</span>&nbsp;&nbsp;<strong>Natural Language Processing for Precision Medicine</strong><br/>
<a href="http://research.microsoft.com/en-us/um/people/hoifung/">Hoifung Poon</a>, <a href="https://www.microsoft.com/en-us/research/people/chrisq/">Chris Quirk</a>, <a href="https://scholar.google.com/citations?user=9qY7NPEAAAAJ&amp;hl=en">Kristina Toutanova</a>, and <a href="https://www.microsoft.com/en-us/research/people/scottyih/">Wen-tau Yih</a>

<div>
<p>We will introduce precision medicine and showcase the vast opportunities for NLP in this burgeoning field with great societal impact. We will review pressing NLP problems, state-of-the art methods, and important applications, as well as datasets, medical resources, and practical issues. The tutorial will provide an accessible overview of biomedicine, and does not presume knowledge in biology or healthcare. The ultimate goal is to reduce the entry barrier for NLP researchers to contribute to this exciting domain.</p>
</div>

<span class="btn btn--small">T2</span>&nbsp;&nbsp;<strong>Multimodal Machine Learning</strong><br/>
<a href="https://www.cs.cmu.edu/~morency/">Louis-Philippe Morency</a> and <a href="http://www.cl.cam.ac.uk/~tb346/">Tadas Baltrusaitis</a>

<div>
<p>Multimodal machine learning is a vibrant multi-disciplinary research field which addresses some of the original goals of artificial intelligence by integrating and modeling multiple communicative modalities, including linguistic, acoustic and visual messages. With the initial research on audio-visual speech recognition and more recently with image and video captioning projects, this research field brings some unique challenges for multimodal researchers given the heterogeneity of the data and the contingency often found between modalities.</p>
 
<p>This tutorial builds upon a recent course taught at Carnegie Mellon University during the Spring 2016 semester (CMU course 11-777) and two tutorials presented at CVPR 2016 and ICMI 2016. The present tutorial will review fundamental concepts of machine learning and deep neural networks before describing the five main challenges in multimodal machine learning: (1) multimodal representation learning, (2) translation & mapping, (3) modality alignment, (4) multimodal fusion and (5) co-learning. The tutorial will also present state-of-the-art algorithms that were recently proposed to solve multimodal applications such as image captioning, video descriptions and visual question-answer. We will also discuss the current and upcoming challenges.</p>
</div>

<span class="btn btn--small">T3</span>&nbsp;&nbsp;<strong>Deep Learning for Semantic Composition</strong><br/>
<a href="http://www.xiaodanzhu.com/about.html">Xiaodan Zhu</a> and <a href="http://egrefen.com">Edward Grefenstette</a>

<div>
<p>Learning representation to model the meaning of text has been a core problem in NLP. The last several years have seen extensive interests on distributional approaches, in which text spans of different granularities are encoded as vectors of numerical values. If properly learned, such representation has showed to achieve the state-of-the-art performance on a wide range of NLP problems.</p>
 
<p>In this tutorial, we will cover the fundamentals and the state-of-the-art research on neural network-based modeling for semantic composition, which aims to learn distributed representation for different granularities of text, e.g., phrases, sentences, or even documents, from their sub-component meaning representation, e.g., word embedding.</p>
</div>


## Afternoon

<span class="btn btn--small">T4</span>&nbsp;&nbsp;<strong>Deep Learning for Dialogue Systems</strong><br/>
<a href="http://www.cs.cmu.edu/~yvchen/">Yun-Nung Chen</a>, <a href="https://www.microsoft.com/en-us/research/people/aslicel/">Asli Celikyilmaz</a>, and <a href="https://research.google.com/pubs/104927.html">Dilek Hakkani-Tur</a>

<div>
<p>In the past decade, goal-oriented spoken dialogue systems have been the most prominent component in today's virtual personal assistants. The classic dialogue systems have rather complex and/or modular pipelines. The advance of deep learning technologies has recently risen the applications of neural models to dialogue modeling. However, how to successfully apply deep learning based approaches to a dialogue system is still challenging. Hence, this tutorial is designed to focus on an overview of the dialogue system development while describing most recent research for building dialogue systems and summarizing the challenges, in order to allow researchers to study the potential improvements of the state-of-the-art dialogue systems. The tutorial material is available at <a href="http://deepdialogue.miulab.tw">http://deepdialogue.miulab.tw</a>.</p>
</div>

<span class="btn btn--small">T5</span>&nbsp;&nbsp;<strong>Beyond Words: Deep Learning for Multi-word Expressions and Collocations</strong><br/>
<a href="https://www.angl.hu-berlin.de/department/staff/kordoni">Valia Kordoni</a>

<div>
<p>Deep learning has recently shown much promise for NLP applications. Traditionally, in most NLP approaches, documents or sentences are represented by a sparse bag-of-words representation. There is now a lot of work which goes beyond this by adopting a distributed representation of words, by constructing a so-called ``neural embedding'' or vector space representation of each word or document. The aim of this tutorial is to go beyond the learning of word vectors and present methods for learning vector representations for Multiword Expressions and bilingual phrase pairs, all of which are useful for various NLP applications.</p>
 
<p>This tutorial aims to provide attendees with a clear notion of the linguistic and distributional characteristics of Multiword Expressions (MWEs), their relevance for the intersection of deep learning and natural language processing, what methods and resources are available to support their use, and what more could be done in the future. Our target audience are researchers and practitioners in machine learning, parsing (syntactic and semantic) and language technology, not necessarily experts in MWEs, who are interested in tasks that involve or could benefit from considering MWEs as a pervasive phenomenon in human language and communication.</p>
</div>

<span class="btn btn--small">T6</span>&nbsp;&nbsp;<strong>Making Better Use of the Crowd</strong><br/>
<a href="http://www.jennwv.com">Jennifer Wortman Vaughan</a>

<div>
<p>Over the last decade, crowdsourcing has been used to harness the power of human computation to solve tasks that are notoriously difficult to solve with computers alone, such as determining whether or not an image contains a tree, rating the relevance of a website, or verifying the phone number of a business.
The natural language processing community was early to embrace crowdsourcing as a tool for quickly and inexpensively obtaining annotated data to train NLP systems. Once this data is collected, it can be handed off to algorithms that learn to perform basic NLP tasks such as translation or parsing. Usually this handoff is where interaction with the crowd ends. The crowd provides the data, but the ultimate goal is to eventually take humans out of the loop. Are there better ways to make use of the crowd? </p>

<p>In this tutorial, I will begin with a showcase of innovative uses of crowdsourcing that go beyond data collection and annotation. I will discuss applications to natural language processing and machine learning, hybrid intelligence or “human in the loop” AI systems that leverage the complementary strengths of humans and machines in order to achieve more than either could achieve alone, and large scale studies of human behavior online. I will then spend the majority of the tutorial diving into recent research aimed at understanding who crowdworkers are, how they behave, and what this should teach us about best practices for interacting with the crowd.</p>
</div>
